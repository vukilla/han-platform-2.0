diff --git a/hmr4d/dataset/bedlam/bedlam.py b/hmr4d/dataset/bedlam/bedlam.py
index 52b75ef..3c5a034 100644
--- a/hmr4d/dataset/bedlam/bedlam.py
+++ b/hmr4d/dataset/bedlam/bedlam.py
@@ -8,7 +8,10 @@ from time import time
 from hmr4d.configs import MainStore, builds
 from hmr4d.utils.smplx_utils import make_smplx
 from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines
-from hmr4d.utils.vis.renderer_utils import simple_render_mesh_background
+try:
+    from hmr4d.utils.vis.renderer_utils import simple_render_mesh_background  # type: ignore
+except Exception:  # pragma: no cover
+    simple_render_mesh_background = None  # type: ignore
 from hmr4d.utils.video_io_utils import read_video_np, save_video
 
 import hmr4d.utils.matrix as matrix
diff --git a/hmr4d/dataset/h36m/h36m.py b/hmr4d/dataset/h36m/h36m.py
index 5370b0d..877bb36 100644
--- a/hmr4d/dataset/h36m/h36m.py
+++ b/hmr4d/dataset/h36m/h36m.py
@@ -14,7 +14,10 @@ from hmr4d.utils.geo_transform import compute_cam_angvel, apply_T_on_points
 from hmr4d.utils.geo.hmr_global import get_tgtcoord_rootparam, get_T_w2c_from_wcparams, get_c_rootparam, get_R_c2gv
 
 from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines
-from hmr4d.utils.vis.renderer import Renderer
+try:
+    from hmr4d.utils.vis.renderer import Renderer  # type: ignore
+except Exception:  # pragma: no cover
+    Renderer = None  # type: ignore
 import imageio
 from hmr4d.utils.video_io_utils import read_video_np
 from hmr4d.utils.net_utils import get_valid_mask, repeat_to_max_len, repeat_to_max_len_dict
diff --git a/hmr4d/dataset/threedpw/threedpw_motion_train.py b/hmr4d/dataset/threedpw/threedpw_motion_train.py
index 2c803fd..c99c1ca 100644
--- a/hmr4d/dataset/threedpw/threedpw_motion_train.py
+++ b/hmr4d/dataset/threedpw/threedpw_motion_train.py
@@ -12,7 +12,10 @@ from hmr4d.dataset.imgfeat_motion.base_dataset import ImgfeatMotionDatasetBase
 from hmr4d.utils.net_utils import get_valid_mask, repeat_to_max_len, repeat_to_max_len_dict
 from hmr4d.utils.smplx_utils import make_smplx
 from hmr4d.utils.video_io_utils import get_video_lwh, read_video_np, save_video
-from hmr4d.utils.vis.renderer_utils import simple_render_mesh_background
+try:
+    from hmr4d.utils.vis.renderer_utils import simple_render_mesh_background  # type: ignore
+except Exception:  # pragma: no cover
+    simple_render_mesh_background = None  # type: ignore
 
 from hmr4d.configs import MainStore, builds
 
diff --git a/hmr4d/utils/body_model/body_model.py b/hmr4d/utils/body_model/body_model.py
index 5f8ac47..112524e 100644
--- a/hmr4d/utils/body_model/body_model.py
+++ b/hmr4d/utils/body_model/body_model.py
@@ -1,4 +1,3 @@
-from turtle import forward
 import numpy as np
 
 import torch
diff --git a/hmr4d/utils/preproc/__init__.py b/hmr4d/utils/preproc/__init__.py
index 6ef3897..55c80e8 100644
--- a/hmr4d/utils/preproc/__init__.py
+++ b/hmr4d/utils/preproc/__init__.py
@@ -1,7 +1,11 @@
 from hmr4d.utils.preproc.tracker import Tracker
 from hmr4d.utils.preproc.vitfeat_extractor import Extractor
 from hmr4d.utils.preproc.vitpose import VitPoseExtractor
-from hmr4d.utils.preproc.relpose.simple_vo import SimpleVO
+try:
+    # SimpleVO depends on pycolmap, which may not be available on Windows.
+    from hmr4d.utils.preproc.relpose.simple_vo import SimpleVO  # type: ignore
+except Exception:  # pragma: no cover
+    SimpleVO = None  # type: ignore
 
 try:
     from hmr4d.utils.preproc.slam import SLAMModel
diff --git a/hmr4d/utils/preproc/tracker.py b/hmr4d/utils/preproc/tracker.py
index b093ed4..3160c56 100644
--- a/hmr4d/utils/preproc/tracker.py
+++ b/hmr4d/utils/preproc/tracker.py
@@ -16,9 +16,24 @@ from hmr4d.utils.video_io_utils import get_video_lwh
 from hmr4d.utils.net_utils import moving_average_smooth
 
 
+def _allowlist_ultralytics_safe_globals() -> None:
+    # PyTorch 2.6+ defaults `torch.load(..., weights_only=True)` and uses a restricted
+    # unpickler. Ultralytics checkpoints reference their model classes, so we must
+    # allowlist them for safe loading on newer torch versions.
+    try:
+        # In practice, the Ultralytics YOLOv8 weights are a trusted checkpoint
+        # (downloaded from Ultralytics releases). To keep GVHMR working on torch>=2.6,
+        # force `weights_only=False` by default.
+        import inspect
+
+        if "weights_only" not in inspect.signature(torch.load).parameters:
+            return
+
+        if getattr(torch.load, "_han_ultralytics_patched", False):
+            return
+
+        _orig_torch_load = torch.load
+
+        def _torch_load_compat(*args, **kwargs):
+            # Force full load to avoid torch>=2.6 safe-unpickler failures on Ultralytics checkpoints.
+            kwargs["weights_only"] = False
+            return _orig_torch_load(*args, **kwargs)
+
+        _torch_load_compat._han_ultralytics_patched = True  # type: ignore[attr-defined]
+        torch.load = _torch_load_compat  # type: ignore[assignment]
+    except Exception:
+        # Best-effort: if the import path changes, Ultralytics may still work, or will
+        # fail with a clearer error prompting manual allowlisting.
+        return
+
+
 class Tracker:
     def __init__(self) -> None:
         # https://docs.ultralytics.com/modes/predict/
+        _allowlist_ultralytics_safe_globals()
         self.yolo = YOLO(PROJ_ROOT / "inputs/checkpoints/yolo/yolov8x.pt")
 
     def track(self, video_path):
diff --git a/hmr4d/utils/vis/renderer.py b/hmr4d/utils/vis/renderer.py
index f4d6232..0f47a5a 100644
--- a/hmr4d/utils/vis/renderer.py
+++ b/hmr4d/utils/vis/renderer.py
@@ -2,20 +2,51 @@ import cv2
 import torch
 import numpy as np
 
-from pytorch3d.renderer import (
-    PerspectiveCameras,
-    TexturesVertex,
-    PointLights,
-    Materials,
-    RasterizationSettings,
-    MeshRenderer,
-    MeshRasterizer,
-    SoftPhongShader,
-)
-from pytorch3d.structures import Meshes
-from pytorch3d.structures.meshes import join_meshes_as_scene
-from pytorch3d.renderer.cameras import look_at_rotation
-from pytorch3d.transforms import axis_angle_to_matrix
+_HAS_PYTORCH3D_RENDERER = True
+_PYTORCH3D_IMPORT_ERROR = None
+
+try:
+    from pytorch3d.renderer import (
+        PerspectiveCameras,
+        TexturesVertex,
+        PointLights,
+        Materials,
+        RasterizationSettings,
+        MeshRenderer,
+        MeshRasterizer,
+        SoftPhongShader,
+    )
+    from pytorch3d.structures import Meshes
+    from pytorch3d.structures.meshes import join_meshes_as_scene
+    from pytorch3d.renderer.cameras import look_at_rotation
+    from pytorch3d.transforms import axis_angle_to_matrix
+except Exception as exc:  # noqa: BLE001
+    # GVHMR's renderer is optional for our pipeline. We run pose extraction only and
+    # pass `--skip_render` to the demo. To keep imports working on Windows where
+    # installing full pytorch3d is painful, we allow this module to import without it.
+    _HAS_PYTORCH3D_RENDERER = False
+    _PYTORCH3D_IMPORT_ERROR = exc
+    PerspectiveCameras = None  # type: ignore[assignment]
+    TexturesVertex = None  # type: ignore[assignment]
+    PointLights = None  # type: ignore[assignment]
+    Materials = None  # type: ignore[assignment]
+    RasterizationSettings = None  # type: ignore[assignment]
+    MeshRenderer = None  # type: ignore[assignment]
+    MeshRasterizer = None  # type: ignore[assignment]
+    SoftPhongShader = None  # type: ignore[assignment]
+    Meshes = None  # type: ignore[assignment]
+    join_meshes_as_scene = None  # type: ignore[assignment]
+    look_at_rotation = None  # type: ignore[assignment]
+    axis_angle_to_matrix = None  # type: ignore[assignment]
+
+
+def _require_pytorch3d() -> None:
+    if not _HAS_PYTORCH3D_RENDERER:
+        raise ImportError(
+            "GVHMR rendering requires `pytorch3d` (renderer/structures). "
+            "Install pytorch3d or run with `--skip_render`. "
+            f"Original error: {_PYTORCH3D_IMPORT_ERROR}"
+        )
 
 from .renderer_tools import get_colors, checkerboard_geometry
 
@@ -105,6 +136,7 @@ def compute_bbox_from_points(X, img_w, img_h, scaleFactor=1.2):
 class Renderer:
     def __init__(self, width, height, focal_length=None, device="cuda", faces=None, K=None, bin_size=None):
         """set bin_size to 0 for no binning"""
+        _require_pytorch3d()
         self.width = width
         self.height = height
         self.bin_size = bin_size
@@ -276,6 +308,7 @@ class Renderer:
 
 
 def create_meshes(verts, faces, colors):
+    _require_pytorch3d()
     """
     :param verts (B, V, 3)
     :param faces (B, F, 3)
@@ -287,6 +320,7 @@ def create_meshes(verts, faces, colors):
 
 
 def get_global_cameras(verts, device="cuda", distance=5, position=(-5.0, 5.0, 0.0)):
+    _require_pytorch3d()
     """This always put object at the center of view"""
     positions = torch.tensor([position]).repeat(len(verts), 1)
     targets = verts.mean(1)
@@ -305,6 +339,7 @@ def get_global_cameras(verts, device="cuda", distance=5, position=(-5.0, 5.0, 0.
 def get_global_cameras_static(
     verts, beta=4.0, cam_height_degree=30, target_center_height=1.0, use_long_axis=False, vec_rot=45, device="cuda"
 ):
+    _require_pytorch3d()
     L, V, _ = verts.shape
 
     # Compute target trajectory, denote as center + scale
diff --git a/hmr4d/utils/wis3d_utils.py b/hmr4d/utils/wis3d_utils.py
index df54d8b..78caa92 100644
--- a/hmr4d/utils/wis3d_utils.py
+++ b/hmr4d/utils/wis3d_utils.py
@@ -1,4 +1,7 @@
-from wis3d import Wis3D
+try:
+    from wis3d import Wis3D  # type: ignore
+except Exception:  # pragma: no cover
+    Wis3D = None  # type: ignore
 from pathlib import Path
 from datetime import datetime
 import torch
@@ -19,6 +22,10 @@ def make_wis3d(output_dir="outputs/wis3d", name="debug", time_postfix=False):
         time_str = datetime.now().strftime("%m%d-%H%M-%S")
         name = f"{name}_{time_str}"
         print(f"Creating Wis3D {name}")
+    if Wis3D is None:
+        raise ImportError(
+            "wis3d is not installed. Install it or avoid calling make_wis3d() in headless/Windows runs."
+        )
     wis3d = Wis3D(output_dir.absolute(), name)
     return wis3d
 
diff --git a/tools/demo/demo.py b/tools/demo/demo.py
index a10fb64..b46afb5 100644
--- a/tools/demo/demo.py
+++ b/tools/demo/demo.py
@@ -27,7 +27,6 @@ from hmr4d.utils.geo_transform import compute_cam_angvel
 from hmr4d.model.gvhmr.gvhmr_pl_demo import DemoPL
 from hmr4d.utils.net_utils import detach_to_cpu, to_cuda
 from hmr4d.utils.smplx_utils import make_smplx
-from hmr4d.utils.vis.renderer import Renderer, get_global_cameras_static, get_ground_params_from_points
 from tqdm import tqdm
 from hmr4d.utils.geo_transform import apply_T_on_points, compute_T_ayfz2ay
 from einops import einsum, rearrange
@@ -52,6 +51,11 @@ def parse_args_to_cfg():
         "If the camera zoom in a lot, you can try 135, 200 or even larger values.",
     )
     parser.add_argument("--verbose", action="store_true", help="If true, draw intermediate results")
+    parser.add_argument(
+        "--skip_render",
+        action="store_true",
+        help="Skip rendering videos. Useful for headless inference and Windows environments without PyTorch3D renderer.",
+    )
     args = parser.parse_args()
 
     # Input
@@ -92,7 +96,7 @@ def parse_args_to_cfg():
         writer.close()
         reader.close()
 
-    return cfg
+    return cfg, args
 
 
 @torch.no_grad()
@@ -201,6 +205,9 @@ def load_data_dict(cfg):
 
 
 def render_incam(cfg):
+    # Import renderer lazily so environments without pytorch3d.renderer can still run inference.
+    from hmr4d.utils.vis.renderer import Renderer
+
     incam_video_path = Path(cfg.paths.incam_video)
     if incam_video_path.exists():
         Log.info(f"[Render Incam] Video already exists at {incam_video_path}")
@@ -243,6 +250,9 @@ def render_incam(cfg):
 
 
 def render_global(cfg):
+    # Import renderer lazily so environments without pytorch3d.renderer can still run inference.
+    from hmr4d.utils.vis.renderer import Renderer, get_global_cameras_static, get_ground_params_from_points
+
     global_video_path = Path(cfg.paths.global_video)
     if global_video_path.exists():
         Log.info(f"[Render Global] Video already exists at {global_video_path}")
@@ -304,7 +314,7 @@ def render_global(cfg):
 
 
 if __name__ == "__main__":
-    cfg = parse_args_to_cfg()
+    cfg, args = parse_args_to_cfg()
     paths = cfg.paths
     Log.info(f"[GPU]: {torch.cuda.get_device_name()}")
     Log.info(f'[GPU]: {torch.cuda.get_device_properties("cuda")}')
@@ -327,8 +337,11 @@ if __name__ == "__main__":
         torch.save(pred, paths.hmr4d_results)
 
     # ===== Render ===== #
-    render_incam(cfg)
-    render_global(cfg)
-    if not Path(paths.incam_global_horiz_video).exists():
-        Log.info("[Merge Videos]")
-        merge_videos_horizontal([paths.incam_video, paths.global_video], paths.incam_global_horiz_video)
+    if args.skip_render:
+        Log.info("[Render] Skipping rendering (--skip_render).")
+    else:
+        render_incam(cfg)
+        render_global(cfg)
+        if not Path(paths.incam_global_horiz_video).exists():
+            Log.info("[Merge Videos]")
+            merge_videos_horizontal([paths.incam_video, paths.global_video], paths.incam_global_horiz_video)
